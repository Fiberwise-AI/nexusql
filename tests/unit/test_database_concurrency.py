"""
Database Concurrency Tests

Tests to ensure the database module handles concurrent access correctly:
- Multiple simultaneous connections
- Concurrent reads and writes
- Transaction isolation
- Deadlock prevention
- Connection pool behavior
- Thread safety
"""

import pytest
from ia_modules.pipeline.test_utils import create_test_execution_context
import asyncio
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from nexusql import DatabaseManager, ConnectionConfig, DatabaseType


@pytest.fixture
def concurrent_db_config():
    """SQLite config for concurrency tests"""
    return ConnectionConfig(
        database_type=DatabaseType.SQLITE,
        database_url="sqlite://:memory:"
    )


class TestConcurrentReads:
    """Test concurrent read operations"""

    def test_multiple_readers_same_connection(self):
        """Test multiple reads on same connection - SQLite will fail across threads"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, value INTEGER)")
        for i in range(100):
            db.execute("INSERT INTO test (value) VALUES (:val)", {"val": i})

        # Multiple concurrent reads from same connection
        # SQLite will fail with thread safety errors - that's expected behavior
        def read_data():
            try:
                rows = db.fetch_all("SELECT * FROM test")
                return len(rows) if rows else 0
            except Exception:
                # Expected for SQLite - connection can't be shared across threads
                return 0

        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(read_data) for _ in range(20)]
            results = [f.result() for f in as_completed(futures)]

        # For SQLite, expect most reads to fail (return 0) due to thread safety
        # At least one should succeed (the one in the original thread)
        assert any(r == 100 for r in results) or all(r == 0 for r in results)

        db.disconnect()

    def test_multiple_readers_different_connections(self):
        """Test multiple readers with separate connections"""
        import tempfile
        import os

        # Use file-based DB for multiple connections
        fd, db_path = tempfile.mkstemp(suffix=".db")
        os.close(fd)

        try:
            # Setup: create and populate database
            config = ConnectionConfig(DatabaseType.SQLITE, f"sqlite:///{db_path}")
            setup_db = DatabaseManager(config)
            setup_db.connect()
            setup_db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, value INTEGER)")
            for i in range(100):
                setup_db.execute("INSERT INTO test (value) VALUES (:val)", {"val": i})
            setup_db.disconnect()

            # Test: multiple readers
            def read_with_own_connection():
                db = DatabaseManager(config)
                db.connect()
                rows = db.fetch_all("SELECT * FROM test")
                count = len(rows)
                db.disconnect()
                return count

            with ThreadPoolExecutor(max_workers=10) as executor:
                futures = [executor.submit(read_with_own_connection) for _ in range(20)]
                results = [f.result() for f in as_completed(futures)]

            # All reads should succeed
            assert all(r == 100 for r in results)

        finally:
            if os.path.exists(db_path):
                os.unlink(db_path)


class TestConcurrentWrites:
    """Test concurrent write operations"""

    def test_sequential_writes(self):
        """Test that sequential writes work correctly"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, value INTEGER)")

        # Sequential writes
        for i in range(100):
            result = db.execute("INSERT INTO test (value) VALUES (:val)", {"val": i})
            assert isinstance(result, list)  # execute() returns list

        # Verify count
        row = db.fetch_one("SELECT COUNT(*) as count FROM test")
        assert row["count"] == 100

        db.disconnect()

    def test_concurrent_writes_different_connections(self):
        """Test concurrent writes with separate connections (file-based DB)"""
        import tempfile
        import os

        fd, db_path = tempfile.mkstemp(suffix=".db")
        os.close(fd)

        try:
            # Setup database
            config = ConnectionConfig(DatabaseType.SQLITE, f"sqlite:///{db_path}")
            setup_db = DatabaseManager(config)
            setup_db.connect()
            setup_db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY AUTOINCREMENT, value INTEGER)")
            setup_db.disconnect()

            # Concurrent writes
            def write_value(value):
                db = DatabaseManager(config)
                db.connect()
                try:
                    result = db.execute("INSERT INTO test (value) VALUES (:val)", {"val": value})
                    db.disconnect()
                    return True
                except Exception:
                    db.disconnect()
                    return False

            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [executor.submit(write_value, i) for i in range(50)]
                results = [f.result() for f in as_completed(futures)]

            # Most or all writes should succeed
            # (SQLite has locking, some might fail with busy)
            success_count = sum(1 for r in results if r)
            assert success_count > 0  # At least some succeeded

            # Verify data
            verify_db = DatabaseManager(config)
            verify_db.connect()
            row = verify_db.fetch_one("SELECT COUNT(*) as count FROM test")
            assert row["count"] == success_count
            verify_db.disconnect()

        finally:
            if os.path.exists(db_path):
                os.unlink(db_path)

    def test_atomic_counter_increment(self):
        """Test atomic counter increments"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE counter (id INTEGER PRIMARY KEY, value INTEGER)")
        db.execute("INSERT INTO counter (id, value) VALUES (:id, :val)", {"id": 1, "val": 0})

        # Increment counter 100 times
        for _ in range(100):
            db.execute("UPDATE counter SET value = value + 1 WHERE id = :id", {"id": 1})

        # Verify final value
        row = db.fetch_one("SELECT value FROM counter WHERE id = :id", {"id": 1})
        assert row["value"] == 100

        db.disconnect()


class TestAsyncConcurrency:
    """Test async/await concurrency"""

    @pytest.mark.asyncio
    async def test_async_concurrent_reads(self):
        """Test concurrent async reads"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, value INTEGER)")
        for i in range(100):
            db.execute("INSERT INTO test (value) VALUES (:val)", {"val": i})

        # Concurrent async reads
        async def async_read():
            # fetch_all is sync, but we can call it concurrently via asyncio
            return len(db.fetch_all("SELECT * FROM test"))

        tasks = [async_read() for _ in range(20)]
        results = await asyncio.gather(*tasks)

        # All should return 100
        assert all(r == 100 for r in results)

        db.disconnect()

    @pytest.mark.asyncio
    async def test_async_concurrent_writes(self):
        """Test concurrent async writes"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY AUTOINCREMENT, value INTEGER)")

        # Concurrent async writes
        async def async_write(value):
            try:
                result = await db.execute_async("INSERT INTO test (value) VALUES (:val)", {"val": value})
                return True
            except Exception:
                return False

        tasks = [async_write(i) for i in range(50)]
        results = await asyncio.gather(*tasks)

        # All should succeed (same connection, SQLite serializes)
        assert all(results)

        # Verify count
        row = db.fetch_one("SELECT COUNT(*) as count FROM test")
        assert row["count"] == 50

        db.disconnect()

    @pytest.mark.asyncio
    async def test_async_mixed_operations(self):
        """Test mixing async reads and writes"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY AUTOINCREMENT, value INTEGER)")

        async def write_and_read(value):
            await db.execute_async("INSERT INTO test (value) VALUES (:val)", {"val": value})
            rows = db.fetch_all("SELECT * FROM test")
            return len(rows)

        tasks = [write_and_read(i) for i in range(10)]
        results = await asyncio.gather(*tasks)

        # Final count should be 10
        row = db.fetch_one("SELECT COUNT(*) as count FROM test")
        assert row["count"] == 10

        db.disconnect()


class TestThreadSafety:
    """Test thread safety of database operations"""

    def test_connection_per_thread(self):
        """Test that each thread should have its own connection"""
        import tempfile
        import os

        fd, db_path = tempfile.mkstemp(suffix=".db")
        os.close(fd)

        try:
            config = ConnectionConfig(DatabaseType.SQLITE, f"sqlite:///{db_path}")

            # Setup
            setup_db = DatabaseManager(config)
            setup_db.connect()
            setup_db.execute("CREATE TABLE test (thread_id INTEGER, value INTEGER)")
            setup_db.disconnect()

            # Each thread writes with its thread ID
            def thread_worker(thread_id):
                db = DatabaseManager(config)
                db.connect()

                for i in range(10):
                    try:
                        result = db.execute(
                            "INSERT INTO test (thread_id, value) VALUES (:tid, :val)",
                            {"tid": thread_id, "val": i}
                        )
                    except Exception as e:
                        print(f"Thread {thread_id} insert {i} failed: {e}")

                db.disconnect()
                return thread_id

            threads = []
            for i in range(5):
                thread = threading.Thread(target=thread_worker, args=(i,))
                threads.append(thread)
                thread.start()

            for thread in threads:
                thread.join()

            # Verify all threads wrote data
            verify_db = DatabaseManager(config)
            verify_db.connect()
            row = verify_db.fetch_one("SELECT COUNT(*) as count FROM test")
            # Should have data from all threads (5 threads * 10 values = up to 50)
            assert row["count"] > 0
            verify_db.disconnect()

        finally:
            if os.path.exists(db_path):
                os.unlink(db_path)

    def test_shared_connection_safety(self):
        """Test that sharing a connection across threads is handled"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY AUTOINCREMENT, thread_id INTEGER)")

        # Multiple threads using SAME connection
        def worker(thread_id):
            results = []
            for i in range(10):
                try:
                    result = db.execute(
                        "INSERT INTO test (thread_id) VALUES (:tid)",
                        {"tid": thread_id}
                    )
                    results.append(True)  # Success if no exception
                except Exception:
                    results.append(False)
                time.sleep(0.001)  # Small delay to encourage interleaving
            return all(results)

        threads = []
        for i in range(3):
            thread = threading.Thread(target=worker, args=(i,))
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        # Check results - SQLite connection might not be thread-safe
        # but should either work or fail gracefully (not crash)
        row = db.fetch_one("SELECT COUNT(*) as count FROM test")
        count = row["count"]

        # Some writes might have succeeded
        assert count >= 0

        db.disconnect()


class TestLocking:
    """Test database locking behavior"""

    def test_write_blocks_write(self):
        """Test that concurrent writes handle locking properly"""
        import tempfile
        import os

        fd, db_path = tempfile.mkstemp(suffix=".db")
        os.close(fd)

        try:
            config = ConnectionConfig(DatabaseType.SQLITE, f"sqlite:///{db_path}")

            # Setup
            setup_db = DatabaseManager(config)
            setup_db.connect()
            setup_db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY AUTOINCREMENT, value INTEGER)")
            setup_db.disconnect()

            # Two connections trying to write simultaneously
            results = []

            def writer(value):
                db = DatabaseManager(config)
                db.connect()
                try:
                    result = db.execute("INSERT INTO test (value) VALUES (:val)", {"val": value})
                    db.disconnect()
                    return True
                except Exception:
                    db.disconnect()
                    return False

            with ThreadPoolExecutor(max_workers=2) as executor:
                future1 = executor.submit(writer, 1)
                future2 = executor.submit(writer, 2)
                results = [future1.result(), future2.result()]

            # At least one should succeed (maybe both if timing works out)
            assert any(results)

        finally:
            if os.path.exists(db_path):
                os.unlink(db_path)


class TestConnectionLifecycle:
    """Test connection creation, reuse, and cleanup"""

    def test_connect_disconnect_cycle(self):
        """Test multiple connect/disconnect cycles"""
        import tempfile
        import os

        # Use file-based DB so data persists across connections
        db_path = tempfile.mktemp(suffix=".db")

        try:
            config = ConnectionConfig(DatabaseType.SQLITE, f"sqlite://{db_path}")
            db = DatabaseManager(config)

            for i in range(10):
                db.connect()
                db.execute("CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY, value INTEGER)")
                db.execute("INSERT INTO test (value) VALUES (:val)", {"val": i})
                row = db.fetch_one("SELECT COUNT(*) as count FROM test")
                assert row["count"] == i + 1
                db.disconnect()
        finally:
            if os.path.exists(db_path):
                os.unlink(db_path)

    def test_connection_reuse(self):
        """Test that connection can be reused"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, value INTEGER)")

        # Reuse same connection for multiple operations
        for i in range(100):
            result = db.execute("INSERT INTO test (value) VALUES (:val)", {"val": i})
            assert isinstance(result, list)  # execute() returns list

        row = db.fetch_one("SELECT COUNT(*) as count FROM test")
        assert row["count"] == 100

        db.disconnect()

    def test_multiple_database_managers(self):
        """Test multiple DatabaseManager instances to same database"""
        import tempfile
        import os

        fd, db_path = tempfile.mkstemp(suffix=".db")
        os.close(fd)

        try:
            config = ConnectionConfig(DatabaseType.SQLITE, f"sqlite:///{db_path}")

            # First manager creates table
            db1 = DatabaseManager(config)
            db1.connect()
            db1.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, value INTEGER)")
            db1.execute("INSERT INTO test (value) VALUES (:val)", {"val": 1})
            db1.disconnect()

            # Second manager reads data
            db2 = DatabaseManager(config)
            db2.connect()
            row = db2.fetch_one("SELECT * FROM test WHERE value = :val", {"val": 1})
            assert row is not None
            db2.execute("INSERT INTO test (value) VALUES (:val)", {"val": 2})
            db2.disconnect()

            # Third manager verifies both writes
            db3 = DatabaseManager(config)
            db3.connect()
            row = db3.fetch_one("SELECT COUNT(*) as count FROM test")
            assert row["count"] == 2
            db3.disconnect()

        finally:
            if os.path.exists(db_path):
                os.unlink(db_path)


class TestRaceConditions:
    """Test handling of race conditions"""

    def test_check_then_insert_race(self):
        """Test classic check-then-insert race condition"""
        import tempfile
        import os

        fd, db_path = tempfile.mkstemp(suffix=".db")
        os.close(fd)

        try:
            config = ConnectionConfig(DatabaseType.SQLITE, f"sqlite:///{db_path}")

            # Setup
            setup_db = DatabaseManager(config)
            setup_db.connect()
            setup_db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, username TEXT UNIQUE)")
            setup_db.disconnect()

            # Two threads trying to insert same username (with check first)
            def check_and_insert(username):
                db = DatabaseManager(config)
                db.connect()

                # Check if exists
                existing = db.fetch_one("SELECT * FROM test WHERE username = :u", {"u": username})

                if existing is None:
                    time.sleep(0.01)  # Simulate processing time
                    # Try to insert
                    try:
                        result = db.execute("INSERT INTO test (username) VALUES (:u)", {"u": username})
                        db.disconnect()
                        return True
                    except Exception:
                        db.disconnect()
                        return False
                else:
                    db.disconnect()
                    return False

            with ThreadPoolExecutor(max_workers=2) as executor:
                future1 = executor.submit(check_and_insert, "duplicate_user")
                future2 = executor.submit(check_and_insert, "duplicate_user")
                results = [future1.result(), future2.result()]

            # One should succeed, one should fail (UNIQUE constraint)
            # But due to race, both might try to insert
            # Database constraint should prevent duplicates

            verify_db = DatabaseManager(config)
            verify_db.connect()
            rows = verify_db.fetch_all("SELECT * FROM test WHERE username = :u", {"u": "duplicate_user"})
            # Should only have one row (UNIQUE constraint enforced)
            assert len(rows) == 1
            verify_db.disconnect()

        finally:
            if os.path.exists(db_path):
                os.unlink(db_path)

    def test_concurrent_unique_inserts(self):
        """Test concurrent inserts with unique constraints"""
        config = ConnectionConfig(DatabaseType.SQLITE, "sqlite://:memory:")
        db = DatabaseManager(config)
        db.connect()

        db.execute("CREATE TABLE test (id INTEGER PRIMARY KEY, email TEXT UNIQUE)")

        # Try to insert same email multiple times
        results = []
        for i in range(5):
            try:
                result = db.execute("INSERT INTO test (email) VALUES (:email)", {"email": "same@example.com"})
                results.append(True)  # Success if no exception
            except Exception:
                results.append(False)

        # Only first should succeed
        assert results[0] is True
        assert all(r is False for r in results[1:])

        # Verify only one row
        row = db.fetch_one("SELECT COUNT(*) as count FROM test")
        assert row["count"] == 1

        db.disconnect()
